# Zadanie 6

Uruchom lokalnie minimum 1 z poniÅ¼szych:
- ollama (patrz: folder `local-ollama`)
- llama.cpp (patrz: folder `local-llama.cpp`)
- DMR (Docker Model Runner)
Wraz z wybranym obrazem (najlepiej FT: _Instruct_).

Zlokalizuj Å›cieÅ¼kÄ™ (lokalnie, na dysku) gdzie model jest przechowywany.
(zerknij na plik [`LINKS-and-STUFF.md`](../LINKS-and-STUFF.md) obok dla porÃ³wnania)

# Zadanie 7

Uruchom wybrany model w google colab.
Skorzystaj z tego linku (jako punkt odniesienia): https://colab.research.google.com/drive/1l8nSfDHWQXV3Db6B4HoDq_rpsy1KYWlq

Ustaw Å›rodowisko uruchomieniowe (CPU/GPU):

![Google Colab Runtime Environment](./colab-file-runtime-env.png)

# Zadanie 8

Ustaw System Prompta (np. â€œ_You are an evil prank-addict. Youâ€™re never serious_â€)
W wybrany przez siebie sposÃ³b:
- Ollama - modelfiles (patrz: `local-ollama`)
- Llama.cpp (UI, http://127.0.0.1:8080) -> settings -> general -> System Message (patrz: `local-llama.cpp`)
- Lokalny model (na bazie kodu z repo: qwen, llama, gemma, etc.; patrz: `local-models`)
- Zewn. model (na bazie kodu z repo: openAI, anthropic, gemini; patrz: `external-model-*`)

I przetestuj poprawne dziaÅ‚anie.

# Zadanie 9

Zwizualizuj Struktury wybranych LLMÃ³w:
- Jupyter i/lub Google Colab.
- Python + Pandas + Data visualization.

Do wyboru (wedle uznania):
- lokalne jupyter notebooks: `M1/jupyter/model-cards.ipynb`
- google colab: https://colab.research.google.com/drive/1jIAl7_QyJy1raIf9FpzYoLGFGknTwuQt
  - konieczny moÅ¼e byÄ‡ upload plikÃ³w (do sesji google colab) z naszego repo z folderu `M1/jupyter/hf-configs` (np. `M1/jupyter/hf-configs/Bielik-7B-Instruct-v0.1-config.json`) z uwagi na to Å¼e google colab we free tier "resetuje sesjÄ™" wraz z plikami.

![google colab file upload](./colab-file-upload.png)

![google colab file upload success](./colab-file-upload-success.png)

# Zadanie 10

- lokalnie folder: `neural-networks`:
  - `neural-networks/xor-network.py`
  - `neural-networks/binary-classification-network.py`
  - `neural-networks/circle-in-square-network.py` - ğŸ”¥ TU JEST ZADANIE ğŸ”¥
- google colab: wersja https://colab.research.google.com/drive/13Uuyl8yT2az4UFa98vvCF9MjTRcCzmYm

"Do-trenuj" sieÄ‡, rozwiÄ…zujÄ…cÄ… problem klasyfikacji binarnej.
  - **OPIS SIECI**: SieÄ‡ ma na celu rozwiÄ…zanie problemu ***klasyfikacji binarnej***, polegajÄ…cego na okreÅ›leniu, czy dany dwuwymiarowy punkt $(x, y)$ leÅ¼y wewnÄ…trz okrÄ™gu o promieniu $0.5$ (etykieta 1) czy poza nim (etykieta 0), gdy punkt znajduje siÄ™ w kwadracie $[-1, 1] \times [-1, 1]$.

Kod jest praktycznie gotowy, ale sieÄ‡ ma niewÅ‚aÅ›ciwie ustawionÄ… strukturÄ™ (sieci - warstwy/neurony) i/lub parametry treningu. Obecnie wszystko jest celowo zanizone.

ğŸ”¥ **Twoje zadanie** ğŸ”¥: przestrukturyzowaÄ‡ sieÄ‡ i/lub przeparametryzowaÄ‡ trening.

ğŸ”¥ **Cel** ğŸ”¥: accuracy 100% przy maÅ‚ym rozmiarze (sieci i treningu). 

Pomoce:
- **TensorBoard**:
  - otwierasz virtualenv (lub cokolwiek czego uÅ¼ywasz do zaleÅ¼noÅ›ci)
  - `tensorboard --logdir=runs` i otwierasz: http://localhost:6006/
  - analityka treningowa bÄ™dzie widoczna po uruchomieniu treningu
  - wszystkie 3 pliki/sieci zapisujÄ… siÄ™ w folderze `runs` (nie musisz nic dodatkowo robiÄ‡)
- **TensorFlow Visualizer**: https://playground.tensorflow.org

# Zadanie 11

Zaprojektuj rozwiÄ…zanie dla poniÅ¼szego flow:
- UÅ¼ytkownik zadaje pytanie (prompt)
- Model prosi o doprecyzowanie (â€œodwrÃ³cenie kontroliâ€)
- UÅ¼ytkownik odpowiada (doprecyzowuje)
- Model moÅ¼e juÅ¼ odpowiedzieÄ‡

# Zadanie 12

AZÃ˜R the CHATDOG. Python.
Folder: `M1/azor-chatdog`

IstniejÄ…ce API klienckie:
- `llama-cpp-python`: `M1/azor-chatdog/src/llm/llama_client.py`
- `google-genai` (gemini): `M1/azor-chatdog/src/llm/gemini_client.py`
ZADANIE - Dodaj nowego klienta/API (wybierz 1):
- Anthropic/zdalnie
- OpenAI/zdalnie (https://api.openai.com)
- OpenAI/REST-lokalnie/ollama
- huggingface/transformers
etc.

# Zadanie 13

AZÃ˜R the CHATDOG. Python.
Folder: `M1/azor-chatdog`

Zadanie - umoÅ¼liwiÄ‡ ustawianie:
- Top P
- Top K
- Temperature
Dla wszystkich dziaÅ‚ajÄ…cych lokalnie klientÃ³w.

docs:
- google-genai: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters#example
- llama-cpp-python: https://llama-cpp-python.readthedocs.io/en/latest/api-reference/
- openai: https://platform.openai.com/docs/api-reference/assistants/object#assistants/object-temperature
etc.
