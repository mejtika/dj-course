# Developer Jutra

Pełny Program Szkolenia

# M1: LLMy i Agenty: Architektura i Działanie

1. Agenty i LLMy: Architektura i Działanie
2. Szczypta Machine Learning
   2.1. Szczypta Machine Learning: Sieci Neuronowe
   2.2. Szczypta Machine Learning: Algebra Liniowa
   2.3. Szczypta Machine Learning: Anatomia LLMów i Architektura Transformers
3. Kwantyzacja
4. Ekosystem LLMowy
5. Modele Lokalne
6. Case Study: Architektura Bielika
7. Budujemy agenty

# M2: Prompty, Kontekst, Halucynacje i Supermoce Nauki

1. Budowanie Kontekstu
2. Redukowanie Halucynacji
3. Modelowanie Odpowiedzi
4. Wzorce Promptów
5. Speech To Text w praktyce
6. Unknown Unknowns
7. Supermoce Nauki

# M3: LLM-assisted coding

1. Zapomnij o Vibe Codingu!
2. Platforms & Agent-Assisted Development 
3. Personalizacja narzędzi
4. Pricing
5. Optymalizacja
6. Multi-tool Flow
7. MCP: Model Context Protocol
8. PRD & Działający Prototyp Produktu
9. Subagents & Spec-Driven

# M4: Inżynieria Produktowa i Architektura Biznesowa

1. Inżynieria Produktowa
2. Eksploracja Nieznanej Domeny
3. Architektura Biznesowa
4. Identyfikacja Interesariuszy Produktu
5. Identyfikacja Zdolności Biznesowych
6. Identyfikacja Procesów Biznesowych
7. Identyfikacja Strumieni Wartości

# M5: Warsztatowe Narzędzia Współpracy

1. Warsztatowe Narzędzia Współpracy
2. Example Mapping
3. User Story Mapping
4. Domain Storytelling
5. Impact Mapping
6. Wardley Mapping
7. Opowiedz o swoim produkcie!

# M6: DevOps: Konteneryzacja

1. Development + Operations
2. Konteneryzacja
3. Docker Engine
4. Wirtualizacja
5. Infrastruktura i Chmura
6. Zarządzanie obrazami
7. Optymalizacje
8. Docker Compose
9. Docker MCP
10. Lokalny Development z Kontenerami
11. Test Containers

# M7: Frontend 

1. Problematyka Frontendu (i Biblioteki Komponentów)
2. Tworzenie UI z AI - Priorytety
3. Frontendowy Tooling okiem Architekta
4. Frontendowe Prompty i Reguły dla AI
5. Modularyzacja i Projektowanie Stanu
6. VSA na froncie
7. Integracja z MCP
8. Testowanie

# M8: Bazy Danych

1. Problematyka Baz Danych
2. Bazo-bebechy
3. Modelowanie bazy z LLM
4. Techniki optymalizacji
5. Integracja z MCP
6. Ile restrykcji w bazie - a ile poza?
7. Współbieżność, Spójność i Transakcje
8. Bazy Dokumentowe
9. JSONB: nie w pełni ustrukturyzowane dane

# M9: Monitoring & Observability

1. Monitoring i obserwowalność
2. Infrastruktura
3. Metryki
4. Logi
5. Tracing
6. Open Telemetry i Instrumentacja
7. Stress Testy: dawaj, wytrzyma

# M10: Backend

1. Problematyka Backendowa
2. Moduły CRUDowe
3. Modelowanie Bounded Contextów
4. Przemodelowanie modułu z archetypami
5. Agregaty, Sagi i reszta zoo DDD
6. Style API
7. OpenAPI: kontrakty dla HTTP
8. Pact: testy kontraktowe
9. Testowanie endpointów

-------------------------
-------------------------
-------------------------

# M1: LLMy i Agenty: Architektura i Działanie

1. Agenty i LLMy: Architektura i Działanie
   > Przyglądamy się wysoko-poziomowej architekturze systemów agentowych, aby "odmagicznić" ich działanie. Spojrzenie na agenty jak na "aplikacje" pomaga zrozumieć ich mocne strony, ograniczenia, potencjalne zastosowania, szanse - oraz kierunki, w jakich ekosystem będzie się rozwijał.
2. Szczypta Machine Learning: Sieci Neuronowe
   > Seria lekcji "Szczypta Machine Learning" ma na celu dać podstawy do zrozumienia, jak działają modele językowe. LLMy również chcemy "odmagicznić". Rozpoczynamy od sieci neuronowych - ich zastosowania, budowy, i celu, jaki pełnią w kontekście LLMów.
3. Szczypta Machine Learning: Algebra Liniowa
   > Wchodzimy w "just enough" matematyki, potrzebnej podczas "wnioskowania" modelu. Nie bój się matematyki - będą wzory, ale prowadzę za rączkę. Celem jest umiejętność czytania white papers bez odruchów wymiotnych ;)
4. Szczypta Machine Learning: Anatomia LLMów i Architektura Transformers
   > Uzbrojeni w podstawy sieci neuronowych i algebry liniowej, przyglądamy się architekturze transformers. Stanowi ona absolutnie fundamentalny punkt odniesienia dla praktycznie wszystkich współczesnych modeli językowych. Nie da się przecenić, jak dużą przewagę w skuteczności wykorzystania LLMów daje zrozumienie, jak działają "pod maską".
5. Kwantyzacja
   > Kwantyzacja to temat, którego wszyscy użytkownicy LLMów doświadczają, a niewielu rozumie. Biznesowo - technika korzystna jest dla vendora, ale dla użytkowników już niekoniecznie - i na owdrót. Poznajemyu mechanizm od środka - i jakie niesie konsekwencje.
6. Ekosystem LLMowy
   > Po "odmagicznieniu" agentów i modeli, przychodzi czas, aby zanurkować w ekosystem. Poznajemy tooling, jego możliwości i specyfikę.
7. Modele Lokalne
   > "Brudzimy sobie ręce", uruchamiając kilka przykładowych modeli lokalnie. Organoleptycznie doświadczamy ograniczeń i wyzwań stojących przed "małymi" modelami.
8. Case Study: Architektura Bielika
   > Syntezujemy wiedzę z poprzednich lekcji, przyglądając się architekturze Bielika - polskiego modelu językowego. Analizujemy jego strukturę i charakterystykę, podsumowując jednocześnie zdobytą wiedzę.
9. Budujemy agenty
   > Budujemy aplikację orkiestrującą LLM. Przyglądamy się wzorcom, ale i wyzwaniom, które przed nami stoją.

# M2: Prompty, Kontekst, Halucynacje i Supermoce Nauki

1. Budowanie Kontekstu
   > Budowanie kontekstu jest fundamentem przy "rozwiązywaniu tasków" które zajmą więcej, niż 1 prompt. Robi dużą różnicę, jak do tego w praktyce podejdziemy.
2. Redukowanie halucynacji
   > Halucynacje to zmora LLMów - ale także coś, co można redukować. Niestety - ostatecznie wyeliminować się ich - przy obecnej architekturze - nie da. Garść praktycznych przykładów.
3. Modelowanie Odpowiedzi
   > Modele Językowe mają jedną świetną umiejętność - umieją w "przetwarzanie języka naturalnego". To oznacza, że możemy bardzo istotnie dostosować odpowiedź do potrzeb, jednocześnie będąc świadomym kontekstu w całym procesie.
4. Wzorce Promptów
   > "Prompt engineering" jako termin był mocno nadużywany - ale faktycznie istnieją pewne wzorce, które mogą znacząco zmienić jakość odpowiedzi - w szczególności, jeśli "idą w parze" z architekturą LLMów (którą poznaliśmy w poprzednim module). Garść praktycznych przykładów.
5. Speech To Text w praktyce
   > AI to nie tylko LLMy - modele wyspecjalizowane w rozpoznawaniu mowy pozwalają drastycznie przyspieszyć nam przelewanie myśli na papier... lub na monitor. Poznajemy tooling, możliwości - i zastosowanie.
6. Unknown Unknowns
   > Absolutnie kluczową umiejętnością Developera Jutra jest efektywna nauka, a w szczególności w stylu just-in-time. Żeby to miało sens, trzeba najpierw zidentyfikować swoje unknown unknowns
7. Supermoce Nauki
   > LLMy to potężne narzędzie, które możemy wykorzystać do nauki. Efekty mogą być naprawdę spektakularne - ale jesteśmy też narażeni na liczne ryzyka, pułapki (o halucynacjach nie wspominając). Garść praktycznych przykładów. Jestem absolutnie przekonany, że to będzie standardowa praktyka, która nota bene zrewolucjonizuje rynek szkoleniowy (którego częścią sam przecież jestem).

# M3: LLM-assisted coding

1. Zapomnij o Vibe Codingu!
   > "Vibe Coding" to być może najbardziej kontrowersyjne hasło związane z LLMami - zaraz po słowie "inteligencja" :) Zanim przejdziemy do kodowania z LLMami na potęgę, uświadommy sobie, że "human in the loop" to często absolutna konieczność dla profesjonalnych developerów. I o ile "vibe coding" znajduje "jakieś" zastosowanie - to twarde rozgraniczenie między "LLM-assisted coding" - a "vibe codingiem" jest kluczowe.
2. Platforms & Agent-Assisted Development 
   > Na tym etapie kodujących agentów jest więcej niż frameworków JavaScriptowych :). Czy to dobrze - nie mnie oceniać ;) Ważne, że narzędzia te są de facto bardzo do siebie podobne - i na tym się koncentrujemy
3. Personalizacja narzędzi
   > Efektywne wykorzystanie kodujących agentów bezwzględnie wymaga zaawansowanej personalizacji. Temat jest obszerny, a narzędzia różnią się między sobą. I tym zajmujemy się w tej lekcji.
4. Pricing
   > Pricing to długoterminowo najważniejszy temat, który może "wywrócić stolik" związany z szeroko pojętym światkiem "AI". Zamiast udawać że go nie ma, i że wszystko jest pięknie i AI czeka tylko świetlana przyszłość - zderzamy się z rzeczywistością. Zaglądamy vendorom tam, gdzie by tego nie chcieli - i wyciągamy wnioski.
5. Optymalizacja
   > Omawianie optymalizacji jest niejako konsekwencją poprzedniej lekcji. To kolejny temat, który devloperzy zdają się ignorować, a który wcale nie wymaga wiele wysiłku, aby go stosować. No chyba że uznamy, że "istotna zmiana podejścia" wymaga wysiłku - to owszem ;)
6. Multi-tool Flow
   > Wykorzystywanie jednocześnie wielu narzędzi może dać ciekawe efekty: nie tylko poprawić jakość, obdlokować nowe możliwości, ale także zredukować koszty. Przyglądamy się kilku praktycznym przykładom.
7. MCP: Model Context Protocol
   > MCP jest systemem typu plug-and-play, który pozwala na mega elastyczną integrację modeli językowych z przeróżnymi usługami. Oczywiście zaglądamy pod maskę - ale także wjeżdżamy w praktyczne zastosowania.
8. PRD & Działający Prototyp Produktu
   > Coś dla fanów tworzenia produktów - od pomysłu, przez PRD, aż do działającego prototypu. Oczywiście z LLMami/agentami w roli pierwszoplanowej.
9. Subagents & Spec-Driven
   > Zawsze marzyłeś o swojej armii agentów? Nie, no, żartuję :P Tak na poważnie - możesz stworzyć i nadać (sub)agentom konkretne role, a następnie zlecać im zadania - i patrzeć, jak marchew rośnie :)

# M4: Inżynieria Produktowa i Architektura Biznesowa

1. Inżynieria Produktowa
   > Mówiąc brutalnie, chciałbym, abyś przestał(a) być "klepaczem kodu", o ile nim jesteś. Lekcja (i cały moduł) ma na celu trochę wyrać Cię z butów i zmienić fokus znacząco. Być może wejdziesz do (pod)świata IT, w którym jeszcze nie byłeś(aś).
2. Eksploracja Nieznanej Domeny
   > Punktem wyjścia do tworzenia dobrego produktu jest zrozumienie domeny, w której działamy. Na pewnym etapie dostęp do eksperta domenowego jest krytyczny - ale jesteśmy w stanie szeroko (i niekoniecznie tylko "wstępnie") rozpoznać problematykę domeny przy użyciu... LLMów. Jestem przekonany, że to będzie standardowa praktyka w niedalekiej przyszłości.
3. Architektura Biznesowa
   > To nie ta architektura, w której się mówio mikroserwisach i monolitach :) Biznes też ma swoje aspekty, które są dla niego budulcem, osią i fundamentem. Poznajemy je - i uczymy się, jak je identyfikować.
4. Identyfikacja Interesariuszy Produktu
   > Rozpoznajemy osoby i/lub instytucje, bez których produkt ani biznes nie miałby racji bytu. Uczymy się, jak ich identyfikować - i dlaczego w ogóle to jest ważne.
5. Identyfikacja Zdolności Biznesowych
   > Zdolności biznesowe są z jednej strony budulcem biznesu, z drugiej - z naszej programistycznej perspektywy - są punktem wyjścia do projektowania architektury systemów IT. Bez zagłębienia się w temat, może się on wydawać abstrakcyjny... ale po tej lekcji projektowanie architektury już nigdy nie będzie takie samo.
6. Identyfikacja Procesów Biznesowych
   > Jeśli zdolności są "budulcem" biznesu, to procesy są jego "ruchomymi częściami". One też będą miały absolutnie kluczowe przełożenie na architekturę. Nie wspominając, że lwia część taktycznego DDD dotyczy właśnie procesów.
7. Identyfikacja Strumieni Wartości
   > Rozumienie Twojego biznesu nie może być kompletne bez uwzględnienia strumieni wartości. Czy to ma przełożenie na programowanie? Oczywiście. A jakie - tego dowiesz się w tej lekcji.

# M5: Warsztatowe Narzędzia Współpracy

1. Warsztatowe Narzędzia Współpracy
   > Rozumiemy już strukturę, więc przyszedł czas na wydobycie od ekspertów domenowych informacji o biznesie... lub może raczej na "twórczą i konstruktywną konfrontację", mającą na celu ujednoliczenie rozumienia mechaniki naszego biznesu? Istnieje masa technik i narzędzi, które Developer Jutra powinien mieć w swoim arsenale.
2. Example Mapping
   > Rozpoczynamy od poziomu blisko kodu i idziemy w kierunku strategii. Example Mapping jest relatywnie prostym i mega przydatnym narzędziem służącym do doprecyzowania, zilustrowania i ustruklturyzowania wymagań. Poprzez - jak sama nazwa wskazuje - przykłady.
3. User Story Mapping
   > User Story Mapping to narzędzie, które pozwala spojrzeć na produkt z perspektywy użytkownika - i zrozumieć, jak jego potrzeby przekładają się na funkcjonalności. To także świetne narzędzie do planowania rozwoju produktu.
4. Domain Storytelling
   > Domain Storytelling, stanowiący swoistą alternatywę do Event Stormingu, pozwala wizualizować procesy biznesowe. Ma mocne zalety i mocne wady - jak wszystko. Jeśli nie jesteś "ze światka Event Stormingu", to być może właśnie to narzędzie najprędzej wykorzystasz w praktyce.
5. Impact Mapping
   > Przechodząc na piętro zdecydowanie strategiczne, szukamy, w jaki sposób możemy wpłynąć na poszczególnych interesariuszy. Chcemy osiągać cele biznesowe - ale "CZYM" i "W JAKI SPOSÓB" wcale nie musi być oczywiste. Impact Mapping to narzędzie, które pomaga w tym procesie.
6. Wardley Mapping
   > Ostatnie na naszej liście to wysoko-poziomowe strategiczne narzędzie, którego "przyswojenie" może - nie przesadzam - zmienić Twój sposób postrzegania rzeczywistości - ale i tego jak się ona zmienia. A co kluczowe - zmieniająca się rzeczywistość wpływa również na Ciebie i Twoją wartość. I to dotyczy tak samo Ciebie, jak i biznesu. Przyglądamy się temu narzędziu z obu perspektyw :)
7. Opowiedz o swoim produkcie!
   > Na koniec, dla rozluźnienia atmosfery, nurkujemy z powrotem w "narzędziówkę" AI-ową. Patrzymy, jak może pomóc nam w opowiadaniu o naszym produkcie.

# M6: DevOps: Konteneryzacja

1. Development + Operations
   > Gdybyśmy zrobili konkurs na najbardziej wypaczone hasło w IT, to "DevOps" byłoby mocnym kandydatem na podium. W tej lekcji przyglądamy się ewolucji procesu wytwórczego i o co tak naprawdę chodzi w DevOps, Team Topologies i DORA. Ale, przede wszystkim "why should you care?".
2. Konteneryzacja
   > W tej lekcji robimy mały "łomot" - bierzemy obiegowe hasła dot. konteneryzacji i punktujemy, że czym innym są buzzwordy i "myślenie życzeniowe", a czym innym zrozumienie, gdzie tkwi sedno danego zagadnienia. W tej lekcji dajemy LLMom odpocząć - bo w następnych będą miały dużo roboty :)
3. Docker Engine
   > Kiedy mówisz "docker", to co konkretnie maz tak naprawdę na myśli? Bo z tym to baaardzo różnie bywa :) W tej lekcji poznajemy nie tylko anatomię dockera - ale i ekosystem wokół. LLMy mają co robić :)
4. Wirtualizacja
   > Fajnie wiedzieć, że kontenery sobie hulają w chmurze. Fajnie wiedzieć, że "security jest ważne". Ale Developer Jutra drąży (poeta napisałby, że "plwa na skorupę i zstępuje do głębi!") - bo jeszcze fajniej jest namacalnie przekonać się o zaletach i wadach "lekkości" kontenerów. Podróż wgłąb OS sponsorują LLMy :)
5. Infrastruktura i Chmura
   > Teraz skaczemy z jednej skrajności (mechaniki wirtualzacji) do drugiej (infrastruktury chmurowej). Przyglądamy się, jak kontenery wpisują się w ekosystem chmurowy - na przykładzie k8s.
6. Zarządzanie obrazami
   > Obrazy - praktycznie - od A do Z. Spuszczamy LLMy z łańcucha i nie bierzemy jeńców :)
7. Optymalizacje
   > Przyjemna lekcja toolingowa - bierzemy na warsztat rozmaite aspekty związane z optymalizacją obrazów kontenerowych. Oczywiście, ręka w rękę z LLMami. To nie tylko kwestia "mniejszego obrazu" - ale także bezpieczeństwa, wydajności, i wielu innych aspektów.
8. Docker Compose
   > "Komponujemy" infrastrukturę ze współpracujących ze sobą kontenerów. Poznajemy możliwości narzędzia - i zajeżdżamy LLMy na maksa...
9. Docker MCP
   > Stricte techniczna lekcja, podczas której ustawiamy serwery MCP dla dockera w "5 smakach". Rozwiązujemy ewentualne problemy, związane z kontenerami, z poziomu agenta.
10. Lokalny Development z Kontenerami
    > Żeby pracować efektywnie, to musimy mieć wygodny tooling. W tej lekcji bierzemy na wasztat DevContainers oraz Docker Compose Watch.
11. Test Containers
    > Konteneryzacja umożliwia nam nie tylko wykorzystanie infrastruktury chmurowej - ale także, poniekąd, rewolucjonizuje kwestie testowania systemów. W tej lekcji zaprzęgamy LLMy do testowania środowiska wielo-komponentowego.

# M7: Frontend 

1. Problematyka Frontendu
   > W tym module NIE "kopiujemy ANF", tylko zaprzęgamy agenty/LLMy do tworzenia frontendu. Najpierw jednak dekomponujemy problematykę frontendową na poszczególne składowe (zarządzanie stanem, type safety, testowalność, itp itd) - aby potem móc maksymalnie delegować robotę agentom.
2. Tworzenie UI z AI - Priorytety
   > Wszyscy mówią - i powszechnie wiadomo - że output z AI trzeba "weryfikować". Zgoda. Ale czy chcesz weryfikować wszystko (w kodzie wyplutym przez agenta)? Nie szkoda Ci czasu? Co warto weryfikować, a co niekoniecznie?
3. Frontendowy Tooling okiem Architekta
   > Dowcipasy dotyczące "frameworków JS przybywających w każdym tygodniem" na szczęście straciły na aktualności. Ale w zależności od stosu, w którym pracujesz, wybór może być nadal mglisty. Wykorzystujemy sprytnie LLMy, aby powiedziały nam nie o tym, jak frameworki twierdzą, że są "blazing fast", tylko jakie faktycznie plusy, minusy i specyfika za nimi stoją. A przy trochę pokodują.
4. Frontendowe Prompty i Reguły dla AI
   > Montujemy "pliki rules" z uwzględnieniem rzeczy "ważnych", ale także odpowiednio dobieramy prompty - aby agenty/LLMy jak najszybciej robiły to, co chcemy.
5. Modularyzacja i Projektowanie Stanu - oraz Heurystyki
   > Za chwilę będziemy "cięli" aplikację na kawałki. Ale zanim to zrobimy, musimy przemyśleć, jakim kluczem naszą aplikację "pokroić". W tej lekcji wykonujemy fazę koncepcyjną, podczas której LLMy odpoczywają - a już zaraz będą miały co robić.
6. VSA na froncie
   > Brudzimy sobie ręce na maksa. Przebudowujemy aplikację z chaotycznego vibe-niew-wiadomo-czego w przemyślany styl Vertical Slices Architecture. Oczywiście - nie my - tylko agent/LLM pod naszym nadzorem.
7. Integracja z MCP
  > Kilka przydatnych MCP do pracy frontendowej - aby nie przeklejać kontekstu agentowi manualnie :)
8. Testowanie
   > LLMy świetnie się nadają do zaprzęgnięcia ich do pisania testów automatycznych. Co też w tej lekcji robimy.

# M8: Bazy Danych

1. Problematyka Baz Danych
   > Nawet jeśli na co dzień piszesz SQLe, to daj się zaskoczyć! W tej lekcji przyglądamy się zaawansowanym zagadnieniom bazodanowym - aby zdiagnozować nasze unknown unknowns.
2. Modelowanie bazy z LLM
   > Dla wybranego obszaru, wykorzystując wiedzę o biznesie (z poprzednich modułów), zaprzęgamy LLMy do zaprojektowania bazy danych w oparciu o ER/SQL. Ogólnie - to robota mocno iteracyjna - gdzie my szczególnie musimy nadzorować proces: albo samodzielnie kierunek narzucać (a LLMowi tylko zlecać czarną robotę) - albo kwestionować, jeśli zlecasz LLMowi rozwiązanie.
3. Ile restrykcji w bazie - a ile poza?
   > Nie tylko jakie restrykcje możemy nałozyć na dane w bazie - ale także - czy w ogóle powinniśmy to robić w bazie?
4. Integracja z MCP
   > Integracja agenta z postgresem poprzez MCP będzie mega przydatna. Garść praktycznych przykładów.
5. Techniki optymalizacji
   > Techniczna lekcja, w której bierzemy na warsztat zagadnienia takie jak: indeksy, zmaterializowane widoki czy EXPLAIN. My wiemy, co chcemy osiągnąć - a agent/LLM dostaje robotę do wykonania.
6. Współbieżność, Spójność i Transakcje
   > Jeden z najważniejszych obszarów bazodanowych, ogólnie. W tej lekcji przyglądamy się różnym modelom spójności, stopniom izolacji iproblemami jakie się wiążą ze współbieżnością (być może nawet bardziej, niż chcemy). Bo jeśli mamy weryfikować kod wypluty z LLMa, to chyba my jesteśmy tymi, co "mają wiedzieć, jak ma być", prawda?
7. Bazy Dokumentowe
   > Nie każda baza musi być relacyjna, prawda? A kiedy, na dobrą sprawę, powinna być relacyjna? W tej lekcji na warsztat bierzemy mongo - i każemy agentowi/LLMowi zakodować to i owo.
8. JSONB: nie w pełni ustrukturyzowane dane
   > W sumie to po co używać mongo, skoro można mieć mongo w postgresie? :) Zaprzęgamy agenta/LLMa aby nie tylko oprowadził nas po świecie JSONB i zakodował co nieco.

# M9: Monitoring & Observability

1. Monitoring i obserwowalność
   > Niektórzy developerzy mawiają: "Dobrze, jeśli (w projekcie) w ogóle jest jakikolwiek monitoring". Z jednej strony coś w tym jest, niestety (z reguły, jak mamy awarię, to na kolana i do Częstochowy)... ale skoro mamy brać temat na warsztat, to rozpocznijmy od "po co" - i co nam taka inwestycja może dać. Uzbrojeni w wiedzę/skille infrastrukturalne wiemy, jaki setup/infrę ma wygenerować LLM.
2. Instrumentacja
   > Żeby słowo stało się ciałem, nasze serwisy trzeba dość intensywnie "okablować". I to pod konkretny stos. Dużo kodowania, oj dużo. Wiadomo kto ;) W tej lekcji wchodzimy w temat metryk, logów i trace'ów - od strony kodu. A LLM oprowadza po toolingu.
3. Open Telemetry
   > Tooling wokół observability nieco przypomina ten javascriptowy... trochę ;) na szczęście powołano do życia standard Open Telemetry, który ma na celu ujednolicenie podejścia. Kodujemy - choć wiadomo, że nie my :) Ale my mamy umieć to zweryfikować.
4. Metryki
   > Nurkujemy w pierwszy z "3 filarów" observability - metryki. Przyglądamy się, co można mierzyć, jak i po co. Wiadomo kto koduje.
5. Logi
   > Przechodzimy do logów - drugiego filaru. Co logować - to niby każdy wie - byle nie za dużo, bo to nie są tanie rzeczy. Tak czy siak, po pierwsze trzeba wyklikać w grafanie dashboardy - a po drugie - okablować odpowiednio kod. Wiadomo kto.
6. Tracing
   > Kto robi to mówić nie trzeba :) Trzeci filar observability - tracing. Obserwujemy, w jaki sposób "ślad" requesty rozciąga się pomiędzy różnymi serwisami.
7. Stress Testy: dawaj, wytrzyma
   > Na koniec modułu - konfigurujemy stress testy, aby mierzyć, jak nasz system radzi sobie pod obciążeniem. Jak zwykle - my musimy wiedzieć co, i po co - a kto koduje to też wiadomo.

# M10: Backend

1. Problematyka Backendowa
   > W tej lekcji przyglądamy się wybranym zagadnieniom backendowym, czyli: domena, modularyzacja, model danych, integracje. Zarysowujemy klucze, wg których będziemy weryfikowali implementację wygenerowaną przez agenta/LLMa.
2. Moduły CRUDowe
   > Jaki CRUD jest - każdy widzi - ale nawet i CRUDa można "zepsuć". Poza kilkoma wskazówkami - w tej lekcji głównie skupiamy się na zaprzęgnięciu agenta/LLMa do skutecznego generowania CRUDów - bo tu weryfikacja jest relatywnie najprostsza.
3. Modelowanie Bounded Contextów
   > Nie wszystko jednak może (czy powinno) być CRUDem. Nie wszystko można "dzielić rzeczownikami". Nawiązujemy do wiedzy z architektury biznesowej (i nie tylko) - i projektujemy granice odpowiedzialności modułów. Są miejsca, gdzie obecne LLMy NIE są pomocne - lub wręcz, przeciwskuteczne. I temu też się przyjrzymy.
4. Przemodelowanie modułu z archetypami
   > Nawet jeśli wydaje się, że "problematyka" modułu została poprawnie pokrojona - to programiści często operują na niewłaściwym poziomie abstrakcji. Archetypów jest dużo (i jest nim też poświęcone inne szkolenie z Kubą, Bartkiem i Sławkiem - które mega polecam). W tej lekcji jednak bierzemy na warsztat przykładowy archetyp, przemodelowujemy to, co mamy. I weryfikujemy - na ile LLM może tu pomóć (czy nie lepiej zrobić to samemu) - lub, precyzyjniej: na jakim poziomie szczegółowości LLM jest "znowu przydatny".
5. Agregaty, Sagi i reszta zoo DDD
   > W tej lekcji przyglądamy się wybranym wzorcom DDD, które mogą pomóc w modelowaniu bardziej złożonych problemów biznesowych. Spuszczenie LLMów łańcucha - w tym przypadku - to totalny strzał, już nawet nie w stopę, a w skroń. Ale, znowu - wykorzystywanie LLMów to nie kwestia 0-1 (binarne tak lub nie). Tę tematykę omawiamy w tej lekcji + oczywiście, kodujemy.
6. Style API
   > Każdy zna HTTP. Ale każdy na innym poziomie :) Dodatkowo - twórcy wielu API z rozpędu mówią, że ich API jest RESTowe. Mhm :) Ilustrujemy mniej znane zagadnienia związane z HTTP, REST i RPC - aby później je zakodować.
7. OpenAPI: kontrakty dla HTTP
   > Zaprzęgamy LLMy do roboty z OpenAPI/Swagger. Automatyzujemy generowanie interfejsów i dbamy o type-safety. Każdy pracuje nad inną częścią - my nad koncepcją, LLM - nad realizacją.
8. Pact: testy kontraktowe
   > "Nasz klient, nasz pan": przyglądamy się konceptowi CDC. Implementujemy testy kontraktowe w Pact.
9. Testowanie endpointów
   > Garść praktycznych technik, narzędzi i przykładów - aby wygodnie testować endpointy. Wiadomo kto robi brudną robotę :)
